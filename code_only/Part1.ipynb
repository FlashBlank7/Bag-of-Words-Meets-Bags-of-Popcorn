{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917fdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入可能需要的包\n",
    "import zipfile\n",
    "import os \n",
    "import sys\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fe02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.dirname('Part1.ipynb')\n",
    "# os.getcwd()\n",
    "# par_dir = os.path.pardir\n",
    "# cur_path = os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a350dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前目录\n",
    "# os.getcwd() #绝对地址\n",
    "# os.path.abspath('.') #绝对地址\n",
    "# os.path.abspath(os.path.dirname(__file__)) # 在jupyter里不能用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f207db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取上一级目录\n",
    "# os.path.abspath('..')\n",
    "# os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n",
    "# os.path.abspath(os.path.dirname(os.getcwd())) # 其实貌似是同os.path.dirname(os.getcwd()的\n",
    "# os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# os.path.join(os.getcwd(), \"..\")\n",
    "\n",
    "# 由于os.path.dirname这个方法很直观，也感觉会很常用，所以以后统一使用该方法和os.getcwd()的组合获取当前和上一级目录名\n",
    "cur_par_dir = os.path.dirname(os.getcwd())\n",
    "# cur_par_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e82774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code', 'data', 'source_data']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取目录下的文件\n",
    "os.listdir(cur_par_dir)\n",
    "# os.listdir(os.path.join(par_dir,'source_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f5869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0 数据准备\n",
    "source_data_path = os.path.join(cur_par_dir,'source_data')\n",
    "obj_par = {\n",
    "    'unzipped_pack_paths':[os.path.join(source_data_path,path) for path in os.listdir(source_data_path)],\n",
    "    'data_target':os.path.join(cur_par_dir,'data')\n",
    "}\n",
    "\n",
    "\n",
    "def show_par(detail = False, entity = ''):\n",
    "    if detail:\n",
    "        print(obj_par[entity])\n",
    "    else:\n",
    "        print(obj_par.keys())\n",
    "    \n",
    "# show_par()\n",
    "unzipped_pack_paths  = obj_par['unzipped_pack_paths']\n",
    "target = obj_par['data_target']\n",
    "# unzipped_pack_paths \n",
    "target\n",
    "unzipped_pack_paths\n",
    "\n",
    "os.path.splitext(unzipped_pack_paths[1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b623725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(unzipped_pack_paths,target):\n",
    "    for path in unzipped_pack_paths:\n",
    "        if os.path.splitext(path)[1] == '.zip':\n",
    "            with zipfile.ZipFile(path) as package:\n",
    "                try:\n",
    "                    package.extractall(target)\n",
    "                except zipfile.BadZipFile:\n",
    "                    print(\"unzip error\")\n",
    "                    \n",
    "def show_datafile(data_path = target):\n",
    "    print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(target):\n",
    "    os.makedirs(target)\n",
    "\n",
    "\n",
    "unzip_data(unzipped_pack_paths, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeb4e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\CodeFiled\\\\NLP_Learning\\\\Kaggle1\\\\working_lab\\\\data\\\\labeledTrainData.tsv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show_datafile()\n",
    "# show_par(detail = True,entity =  'data_target')\n",
    "os.path.join(obj_par['data_target'],'labeledTrainData.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91551c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据处理\n",
    "# 导入\n",
    "\n",
    "# 没有delimiter=\"\\t\" 是读不了这个数据的\n",
    "raw_labeled_review = pd.read_csv(os.path.join(obj_par['data_target'],'labeledTrainData.tsv'), delimiter=\"\\t\", quoting=3)\n",
    "raw_labeled_review.head\n",
    "\n",
    "row_num, col_num = raw_labeled_review.shape\n",
    "# raw_labeled_review.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08120e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据清洁1：网上爬的，清一下HMTL标签。根据字符串对象创建一个BeautifulSoup对象可以直接提取出不含标签的文字。\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sample1 = raw_labeled_review['review'][0]\n",
    "\n",
    "sample1_soup = BeautifulSoup(sample1)\n",
    "\n",
    "sample1\n",
    "sample1_soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f51b1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语义精炼\n",
    "# 数据处理1：为了方便，在这里不将特殊的标点当做词汇，直接去除，即只保留是字符的，不是字母的字符用空格替换\n",
    "import re\n",
    "pattern = '[^a-zA-Z]'\n",
    "\n",
    "sample2 = sample1_soup.get_text()\n",
    "re.sub(pattern, ' ', sample2)\n",
    "\n",
    "sample2 = sample2.lower()\n",
    "sample2 = sample2.split(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7621088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理2：去除掉语义信息少的高频词\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopword_corpus = stopwords.words('English')\n",
    "# 把字符串变成小写后，分离成词表，再与stopwords的词表对比，得到不含stopwords的词表\n",
    "\n",
    "sample3 = [w for w in sample2 if not w in stopword_corpus]\n",
    "\n",
    "# \" \".join(sample3)\n",
    "# sample3\n",
    "\n",
    "stopword_corpus = set(stopword_corpus)# 加快速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d107e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理函数，只针对单条数据，后面做循环就好\n",
    "def review_proc(review):\n",
    "    rev_HTML_review = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    rev_pun = re.sub('[^a-zA-Z]', \" \", rev_HTML_review)\n",
    "    \n",
    "    lowor_review_list = rev_pun.lower().split(\" \")\n",
    "    \n",
    "    rev_stop_review_list = [w for w in lowor_review_list if not w in stopword_corpus]\n",
    "    \n",
    "    return ' '.join(rev_stop_review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323e6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FlashBlack7\\AppData\\Local\\Temp\\ipykernel_49008\\3990676818.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  rev_HTML_review = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "processed_reviews = []\n",
    "\n",
    "nums, _ = raw_labeled_review.shape\n",
    "\n",
    "for i in range(0, nums):\n",
    "    processed_reviews.append(review_proc(raw_labeled_review['review'][i]))\n",
    "\n",
    "# processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fdace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Bags of words：思想，基于数据和常用词给出一个vocabulary,对应一个高维的稀疏向量，对于一个句子，统计里面存在于vocalbulary里词汇的个数，并记录在对应分量位置\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words = None,\n",
    "    analyzer= \"word\",\n",
    "    tokenizer = None,\n",
    "    max_features = 5000)\n",
    "\n",
    "#_.fit_transform() 方法接受一个文本数组，其中每个元素都是一篇文章或一条消息。最后返回一个稀疏矩阵，每行为一样本\n",
    "train_data = vectorizer.fit_transform(processed_reviews) \n",
    "\n",
    "# train_data = train_data.toarray() #现在貌似会自动转成numpy的数组了\n",
    "# type(train_data)\n",
    "# dist = np.sum(train_data, axis=0)\n",
    "# dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80877126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plus:显示当下定义的函数\n",
    "def func1():\n",
    "    pass\n",
    "\n",
    "\n",
    "def show_funcs():\n",
    "    print([name for name in dir() if callable(locals().get(name)) and isinstance(locals().get(name), type(func1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f99891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 模型训练\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators = 100,verbose=True)\n",
    "# forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "\n",
    "# forest  = forest.fit(train_data, raw_labeled_review['sentiment'],verbose=True)\n",
    "# forest  = forest.fit(train_data, raw_labeled_review['sentiment'])\n",
    "# raw_labeled_review['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4207ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "# formatter = logging.Formatter(' %(message)s')\n",
    "\n",
    "# console_handler = logging.StreamHandler()\n",
    "# console_handler.setLevel(logging.INFO)\n",
    "# console_handler.setFormatter(formatter)\n",
    "\n",
    "# logger.addHandler(console_handler)\n",
    "\n",
    "# for i in range(10):\n",
    "#     logger.debug('Iteration %d', i)\n",
    "#     logger.info('Iteration %d', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "382b1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sklearn的模型序列化有两种方法:\n",
    "# 二进制化保存成文件\n",
    "# import pickle\n",
    "\n",
    "\n",
    "# with open(os.path.join(os.getcwd(),'RandomForest.pkl'), 'wb') as file:\n",
    "#     pickle.dump(forest, file)\n",
    "\n",
    "# # 加载模型\n",
    "# with open(os.path.join(os.getcwd(),'RandomForest.pkl'), 'rb') as file:\n",
    "#     forest = pickle.load(file)\n",
    "\n",
    "# 压缩到磁盘\n",
    "import joblib\n",
    "\n",
    "# joblib.dump(forest, os.path.join(os.getcwd(),'RandomForest.joblib' ))\n",
    "\n",
    "forest = joblib.load(os.path.join(os.getcwd(),'RandomForest.joblib' ))\n",
    "# 以上两个方法根据搜索结果，joblib更适合大数据，因此以后默认采用后者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f54ffec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 在测试集上运行模型\n",
    "# 解压\n",
    "# os.listdir(obj_par['data_target']))\n",
    "raw_test_reviews = pd.read_csv(os.path.join(obj_par['data_target'],'testData.tsv'), delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "rows, _ = raw_test_reviews.shape\n",
    "\n",
    "clean_text_reviews = []\n",
    "\n",
    "\n",
    "# raw_test_reviews.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59fe09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FlashBlack7\\AppData\\Local\\Temp\\ipykernel_49008\\3990676818.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  rev_HTML_review = BeautifulSoup(review).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: %d 1000\n",
      "iteration: %d 2000\n",
      "iteration: %d 3000\n",
      "iteration: %d 4000\n",
      "iteration: %d 5000\n",
      "iteration: %d 6000\n",
      "iteration: %d 7000\n",
      "iteration: %d 8000\n",
      "iteration: %d 9000\n",
      "iteration: %d 10000\n",
      "iteration: %d 11000\n",
      "iteration: %d 12000\n",
      "iteration: %d 13000\n",
      "iteration: %d 14000\n",
      "iteration: %d 15000\n",
      "iteration: %d 16000\n",
      "iteration: %d 17000\n",
      "iteration: %d 18000\n",
      "iteration: %d 19000\n",
      "iteration: %d 20000\n",
      "iteration: %d 21000\n",
      "iteration: %d 22000\n",
      "iteration: %d 23000\n",
      "iteration: %d 24000\n",
      "iteration: %d 25000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, rows):\n",
    "    clean_text_reviews.append(review_proc(raw_test_reviews[\"review\"][i]))\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(\"iteration: %d\",i+1)\n",
    "\n",
    "test_data = vectorizer.transform(clean_text_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9edeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest.predict(test_data)\n",
    "\n",
    "submission = pd.DataFrame({'id': raw_test_reviews['id'], 'sentiment':result})\n",
    "submission.to_csv('Bag_of_Words_model.csv', index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06106845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"2155_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"59_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"2531_1\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"7772_8\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"11465_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  sentiment\n",
       "0      \"12311_10\"          1\n",
       "1        \"8348_2\"          0\n",
       "2        \"5828_4\"          1\n",
       "3        \"7186_2\"          1\n",
       "4       \"12128_7\"          1\n",
       "...           ...        ...\n",
       "24995   \"2155_10\"          1\n",
       "24996     \"59_10\"          1\n",
       "24997    \"2531_1\"          0\n",
       "24998    \"7772_8\"          1\n",
       "24999  \"11465_10\"          1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
